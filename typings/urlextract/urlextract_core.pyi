"""
This type stub file was generated by pyright.
"""

from urlextract.cachefile import CacheFile

"""
urlextract_core.py - file with definition of URLExtract class and urlextract cli

.. Created on 2016-07-29
.. Licence MIT
.. codeauthor:: Jan Lipovsk√Ω <janlipovsky@gmail.com>, janlipovsky.cz
.. contributors: https://github.com/lipoja/URLExtract/graphs/contributors
"""
__version__ = ...
DEFAULT_LIMIT = ...

class URLExtract(CacheFile):
    """
    Class for finding and extracting URLs from given string.

    **Examples:**

    .. code-block:: python

        from urlextract import URLExtract

        extractor = URLExtract()
        urls = extractor.find_urls("Let's have URL example.com example.")
        print(urls) # prints: ['example.com']

        # Another way is to get a generator over found URLs in text:
        for url in extractor.gen_urls(example_text):
            print(url) # prints: ['example.com']

        # Or if you want to just check if there is at least one URL in text:
        if extractor.has_urls(example_text):
            print("Given text contains some URL")
    """

    _hostname_re = ...
    _enclosure = ...
    _ipv4_tld = ...
    _ignore_list = ...
    _permit_list = ...
    _limit = ...
    def __init__(self, extract_email=..., cache_dns=..., extract_localhost=..., limit=..., **kwargs) -> None:
        """
        Initialize function for URLExtract class.
        Tries to get cached TLDs, if cached file does not exist it will try
        to download new list from IANA and save it to cache file.

        :param bool extract_email: True if we want to extract email from text.
            Disabled by default
        :param bool cache_dns: True replaces socket DNS lookup with caching
            equivalent provided by dnspython.
            Enabled by default
        :param bool extract_localhost: True if we want to extract 'localhost'
            as URL from text.
            Enabled by default
        """
        ...
    @property
    def extract_email(self):  # -> bool:
        """
        If set to True email will be extracted from text

        :rtype: bool
        """
        ...
    @extract_email.setter
    def extract_email(self, extract):  # -> None:
        """
        Set if emails will be extracted from text

        :param bool extract: True if emails should be extracted False otherwise
        """
        ...
    @property
    def extract_localhost(self):  # -> bool:
        """
        If set to True 'localhost' will be extracted as URL from text

        :rtype: bool
        """
        ...
    @extract_localhost.setter
    def extract_localhost(self, enable):  # -> None:
        """
        Set if 'localhost' will be extracted as URL from text

        :param bool enable: True if localhost' should be extracted
            False otherwise
        """
        ...
    @property
    def ignore_list(self):  # -> set[Unknown]:
        """
        Returns set of URLs on ignore list

        :return: Returns set of ignored URLs
        :rtype: set(str)
        """
        ...
    @ignore_list.setter
    def ignore_list(self, ignore_list):  # -> None:
        """
        Set of URLs to be ignored (not returned) while extracting from text

        :param set(str) ignore_list: set of URLs
        """
        ...
    def load_ignore_list(self, file_name):  # -> None:
        """
        Load URLs from file into ignore list

        :param str file_name: path to file containing URLs
        """
        ...
    @property
    def permit_list(self):  # -> set[Unknown]:
        """
        Returns set of URLs that can be processed

        :return: Returns set of URLs that can be processed
        :rtype: set(str)
        """
        ...
    @permit_list.setter
    def permit_list(self, permit_list):  # -> None:
        """
        Set of URLs that can be processed

        :param set(str) permit_list: set of URLs
        """
        ...
    def load_permit_list(self, file_name):  # -> None:
        """
        Load URLs from file into permit list

        :param str file_name: path to file containing URLs
        """
        ...
    def update(self):  # -> bool:
        """
        Update TLD list cache file.

        :return: True if update was successful False otherwise
        :rtype: bool
        """
        ...
    def update_when_older(self, days):  # -> bool:
        """
        Update TLD list cache file if the list is older than
        number of days given in parameter `days` or if does not exist.

        :param int days: number of days from last change
        :return: True if update was successful, False otherwise
        :rtype: bool
        """
        ...
    @staticmethod
    def get_version():  # -> str:
        """
        Returns version number.

        :return: version number
        :rtype: str
        """
        ...
    def get_after_tld_chars(self):  # -> list[str]:
        """
        Returns list of chars that are allowed after TLD

        :return: list of chars that are allowed after TLD
        :rtype: list
        """
        ...
    def set_after_tld_chars(self, after_tld_chars):  # -> None:
        """
        Set chars that are allowed after TLD.

        :param list after_tld_chars: list of characters
        """
        ...
    def get_stop_chars_left(self):  # -> set[str] | set[Unknown]:
        """
        Returns set of stop chars for text on left from TLD.

        :return: set of stop chars
        :rtype: set
        """
        ...
    def set_stop_chars_left(self, stop_chars):  # -> None:
        """
        Set stop characters for text on left from TLD.
        Stop characters are used when determining end of URL.

        :param set stop_chars: set of characters
        :raises: TypeError
        """
        ...
    def get_stop_chars_right(self):  # -> set[str] | set[Unknown]:
        """
        Returns set of stop chars for text on right from TLD.

        :return: set of stop chars
        :rtype: set
        """
        ...
    def set_stop_chars_right(self, stop_chars):  # -> None:
        """
        Set stop characters for text on right from TLD.
        Stop characters are used when determining end of URL.

        :param set stop_chars: set of characters
        :raises: TypeError
        """
        ...
    def get_enclosures(
        self,
    ):  # -> set[tuple[Literal['('], Literal[')']] | tuple[Literal['{'], Literal['}']] | tuple[Literal['['], Literal[']']] | tuple[Literal['"'], Literal['"']] | tuple[Literal['\\'], Literal['\\']] | tuple[Literal['\''], Literal['\'']] | tuple[Literal['`'], Literal['`']]]:
        """
        Returns set of enclosure pairs that might be used to enclosure URL.
        For example brackets (example.com), [example.com], {example.com}

        :return: set of tuple of enclosure characters
        :rtype: set(tuple(str,str))
        """
        ...
    def add_enclosure(self, left_char, right_char):  # -> None:
        """
        Add new enclosure pair of characters. That and should be removed
        when their presence is detected at beginning and end of found URL

        :param str left_char: left character of enclosure pair - e.g. "("
        :param str right_char: right character of enclosure pair - e.g. ")"
        """
        ...
    def remove_enclosure(self, left_char, right_char):  # -> None:
        """
        Remove enclosure pair from set of enclosures.

        :param str left_char: left character of enclosure pair - e.g. "("
        :param str right_char: right character of enclosure pair - e.g. ")"
        """
        ...
    def gen_urls(self, text, check_dns=..., get_indices=..., with_schema_only=...):
        """
        Creates generator over found URLs in given text.

        :param str text: text where we want to find URLs
        :param bool check_dns: filter results to valid domains
        :param bool get_indices: whether to return beginning and
            ending indices as (<url>, (idx_begin, idx_end))
        :param bool with_schema_only: get domains with schema only
        :yields: URL or URL with indices found in text or empty string if nothing was found
        :rtype: str|tuple(str, tuple(int, int))
        """
        ...
    def find_urls(self, text, only_unique=..., check_dns=..., get_indices=..., with_schema_only=...):  # -> list[Unknown]:
        """
        Find all URLs in given text.

        :param str text: text where we want to find URLs
        :param bool only_unique: return only unique URLs
        :param bool check_dns: filter results to valid domains
        :return: list of URLs found in text
        :param bool get_indices: whether to return beginning and
            ending indices as (<url>, (idx_begin, idx_end))
        :param bool with_schema_only: get domains with schema only
            (e.g. https://janlipovsky.cz but not example.com)
        :rtype: list

        :raises URLExtractError: Raised when count of found URLs reaches
            given limit. Processed URLs are returned in `data` argument.
        """
        ...
    def has_urls(self, text, check_dns=..., with_schema_only=...):  # -> bool:
        """
        Checks if text contains any valid URL.
        Returns True if text contains at least one URL.

        :param text: text where we want to find URLs
        :param bool check_dns: filter results to valid domains
        :param bool with_schema_only: consider domains with schema only
        :return: True if et least one URL was found, False otherwise
        :rtype: bool
        """
        ...

class URLExtractError(Exception):
    """
    Raised when some error occurred during processing URLs.

    Attributes:
        message -- explanation of the error
        data -- input expression in which the error occurred
    """

    def __init__(self, message, data) -> None: ...

def report_issue(func):  # -> (*args: Unknown, **kwargs: Unknown) -> Unknown:
    """Friendly message with link to GitHub for easier reporting"""
    ...

def dns_cache_install(): ...

if __name__ == "__main__": ...
